{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 00: Data Exploration & Schema Discovery\n",
        "\n",
        "## Purpose\n",
        "This notebook explores the raw CSV files (`holdings.csv` and `trades.csv`) to understand their structure, identify key columns, detect data quality issues, and generate schema documentation.\n",
        "\n",
        "## Key Features\n",
        "- Loads and examines CSV files\n",
        "- Identifies fund identifiers, date columns, and P&L columns\n",
        "- Performs data quality checks (missing values, duplicates, anomalies)\n",
        "- Generates `schema_info.json` and `column_mappings.json` for downstream use\n",
        "\n",
        "## Column Mapping Strategy\n",
        "**IMPORTANT**: CSV files use different column names than the database:\n",
        "- CSV: `PL_YTD`, `PL_MTD`, `PL_QTD`, `PL_DTD` (uppercase with underscores)\n",
        "- Database: `plytd`, `plmtd`, `plqtd`, `pldtd` (lowercase, no underscores)\n",
        "- CSV: `MV_Base`, `MV_Local`, `PortfolioName` (PascalCase)\n",
        "- Database: `mvbase`, `mvlocal`, `portfolioname` (lowercase)\n",
        "\n",
        "This notebook documents the CSV structure. The mapping to database column names happens in `01_data_ingestion.ipynb`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Cell 1: Imports and Setup\n",
        "import pandas as pd\n",
        "import json\n",
        "from pathlib import Path\n",
        "from datetime import datetime, timezone\n",
        "\n",
        "# Project root\n",
        "project_root = Path.cwd().parent\n",
        "data_dir = project_root / \"data\"\n",
        "\n",
        "print(\"✅ Imports loaded\")\n",
        "print(f\"   Data directory: {data_dir}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Cell 2: Load CSV Files\n",
        "holdings_file = data_dir / \"holdings.csv\"\n",
        "trades_file = data_dir / \"trades.csv\"\n",
        "\n",
        "# Load holdings\n",
        "holdings_df = pd.read_csv(holdings_file)\n",
        "print(f\"✅ Holdings loaded: {len(holdings_df)} rows, {len(holdings_df.columns)} columns\")\n",
        "\n",
        "# Load trades\n",
        "trades_df = pd.read_csv(trades_file)\n",
        "print(f\"✅ Trades loaded: {len(trades_df)} rows, {len(trades_df.columns)} columns\")\n",
        "\n",
        "# Display column names\n",
        "print(f\"\\nHoldings columns: {list(holdings_df.columns)}\")\n",
        "print(f\"\\nTrades columns: {list(trades_df.columns)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Cell 3: Identify Key Columns\n",
        "\n",
        "def identify_fund_column(df: pd.DataFrame) -> str:\n",
        "    \"\"\"Identify fund identifier column.\"\"\"\n",
        "    candidates = [\"PortfolioName\", \"portfolioname\", \"Fund\", \"fund\"]\n",
        "    for col in candidates:\n",
        "        if col in df.columns:\n",
        "            return col\n",
        "    return None\n",
        "\n",
        "def identify_date_column(df: pd.DataFrame) -> str:\n",
        "    \"\"\"Identify date column.\"\"\"\n",
        "    candidates = [\"AsOfDate\", \"asofdate\", \"TradeDate\", \"tradedate\", \"Date\", \"date\"]\n",
        "    for col in candidates:\n",
        "        if col in df.columns:\n",
        "            return col\n",
        "    return None\n",
        "\n",
        "def identify_pnl_columns(df: pd.DataFrame) -> list:\n",
        "    \"\"\"Identify P&L columns (from CSV - may have underscores).\"\"\"\n",
        "    pnl_cols = []\n",
        "    for col in df.columns:\n",
        "        col_lower = col.lower()\n",
        "        if \"pl_ytd\" in col_lower or \"plytd\" in col_lower:\n",
        "            pnl_cols.append(col)\n",
        "        elif \"pl_mtd\" in col_lower or \"plmtd\" in col_lower:\n",
        "            pnl_cols.append(col)\n",
        "        elif \"pl_qtd\" in col_lower or \"plqtd\" in col_lower:\n",
        "            pnl_cols.append(col)\n",
        "        elif \"pl_dtd\" in col_lower or \"pldtd\" in col_lower:\n",
        "            pnl_cols.append(col)\n",
        "    return pnl_cols\n",
        "\n",
        "# Identify columns\n",
        "holdings_fund_col = identify_fund_column(holdings_df)\n",
        "holdings_date_col = identify_date_column(holdings_df)\n",
        "holdings_pnl_cols = identify_pnl_columns(holdings_df)\n",
        "\n",
        "trades_fund_col = identify_fund_column(trades_df)\n",
        "trades_date_col = identify_date_column(trades_df)\n",
        "trades_pnl_cols = identify_pnl_columns(trades_df)\n",
        "\n",
        "print(\"Holdings:\")\n",
        "print(f\"  Fund column: {holdings_fund_col}\")\n",
        "print(f\"  Date column: {holdings_date_col}\")\n",
        "print(f\"  P&L columns: {holdings_pnl_cols}\")\n",
        "\n",
        "print(\"\\nTrades:\")\n",
        "print(f\"  Fund column: {trades_fund_col}\")\n",
        "print(f\"  Date column: {trades_date_col}\")\n",
        "print(f\"  P&L columns: {trades_pnl_cols}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Cell 4: Data Quality Checks\n",
        "\n",
        "def check_missing_data(df: pd.DataFrame, name: str):\n",
        "    \"\"\"Check for missing values.\"\"\"\n",
        "    print(f\"\\n{name} - Missing Data:\")\n",
        "    for col in df.columns:\n",
        "        missing = df[col].isna().sum()\n",
        "        pct = (missing / len(df)) * 100\n",
        "        if missing > 0:\n",
        "            print(f\"  {col}: {missing} ({pct:.1f}%)\")\n",
        "\n",
        "def check_duplicates(df: pd.DataFrame, name: str):\n",
        "    \"\"\"Check for duplicate rows.\"\"\"\n",
        "    duplicates = df.duplicated().sum()\n",
        "    print(f\"\\n{name} - Duplicates: {duplicates} rows\")\n",
        "\n",
        "def check_unique_funds(df: pd.DataFrame, fund_col: str, name: str):\n",
        "    \"\"\"List unique funds.\"\"\"\n",
        "    if fund_col and fund_col in df.columns:\n",
        "        unique_funds = df[fund_col].unique()\n",
        "        print(f\"\\n{name} - Unique Funds: {len(unique_funds)}\")\n",
        "        print(f\"  Sample: {list(unique_funds[:10])}\")\n",
        "\n",
        "# Run checks\n",
        "check_missing_data(holdings_df, \"Holdings\")\n",
        "check_duplicates(holdings_df, \"Holdings\")\n",
        "check_unique_funds(holdings_df, holdings_fund_col, \"Holdings\")\n",
        "\n",
        "check_missing_data(trades_df, \"Trades\")\n",
        "check_duplicates(trades_df, \"Trades\")\n",
        "check_unique_funds(trades_df, trades_fund_col, \"Trades\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Cell 5: Generate Schema Info\n",
        "\n",
        "# Create schema_info.json (CSV column names - for reference)\n",
        "schema_info = {\n",
        "    \"holdings\": {\n",
        "        \"columns\": list(holdings_df.columns),\n",
        "        \"fund_column\": holdings_fund_col,\n",
        "        \"date_column\": holdings_date_col,\n",
        "        \"pnl_columns\": holdings_pnl_cols,\n",
        "        \"shape\": list(holdings_df.shape),\n",
        "        \"dtypes\": {col: str(dtype) for col, dtype in holdings_df.dtypes.items()},\n",
        "        \"unique_funds\": int(holdings_df[holdings_fund_col].nunique()) if holdings_fund_col else 0,\n",
        "        \"sample_funds\": list(holdings_df[holdings_fund_col].unique()[:10]) if holdings_fund_col else []\n",
        "    },\n",
        "    \"trades\": {\n",
        "        \"columns\": list(trades_df.columns),\n",
        "        \"fund_column\": trades_fund_col,\n",
        "        \"date_column\": trades_date_col,\n",
        "        \"pnl_columns\": trades_pnl_cols,\n",
        "        \"shape\": list(trades_df.shape),\n",
        "        \"dtypes\": {col: str(dtype) for col, dtype in trades_df.dtypes.items()},\n",
        "        \"unique_funds\": int(trades_df[trades_fund_col].nunique()) if trades_fund_col else 0,\n",
        "        \"sample_funds\": list(trades_df[trades_fund_col].unique()[:10]) if trades_fund_col else []\n",
        "    }\n",
        "}\n",
        "\n",
        "# Save schema_info.json\n",
        "schema_info_path = project_root / \"notebook2\" / \"schema_info.json\"\n",
        "with open(schema_info_path, \"w\") as f:\n",
        "    json.dump(schema_info, f, indent=2)\n",
        "\n",
        "print(f\"✅ schema_info.json saved to {schema_info_path}\")\n",
        "print(f\"   Holdings: {len(schema_info['holdings']['columns'])} columns\")\n",
        "print(f\"   Trades: {len(schema_info['trades']['columns'])} columns\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Cell 6: Generate Column Mappings (CSV → Database)\n",
        "\n",
        "# CRITICAL: This mapping converts CSV column names to database column names\n",
        "# Database uses lowercase, no underscores for P&L columns\n",
        "\n",
        "def create_column_mapping(csv_columns: list) -> dict:\n",
        "    \"\"\"Create mapping from CSV columns to database columns.\"\"\"\n",
        "    mapping = {}\n",
        "    \n",
        "    for col in csv_columns:\n",
        "        col_lower = col.lower()\n",
        "        \n",
        "        # P&L columns: PL_YTD → plytd, PL_MTD → plmtd, etc.\n",
        "        if \"pl_ytd\" in col_lower or col_lower == \"plytd\":\n",
        "            mapping[col] = \"plytd\"\n",
        "        elif \"pl_mtd\" in col_lower or col_lower == \"plmtd\":\n",
        "            mapping[col] = \"plmtd\"\n",
        "        elif \"pl_qtd\" in col_lower or col_lower == \"plqtd\":\n",
        "            mapping[col] = \"plqtd\"\n",
        "        elif \"pl_dtd\" in col_lower or col_lower == \"pldtd\":\n",
        "            mapping[col] = \"pldtd\"\n",
        "        # Market value columns\n",
        "        elif \"mv_base\" in col_lower or col_lower == \"mvbase\":\n",
        "            mapping[col] = \"mvbase\"\n",
        "        elif \"mv_local\" in col_lower or col_lower == \"mvlocal\":\n",
        "            mapping[col] = \"mvlocal\"\n",
        "        # Other columns: convert to lowercase\n",
        "        else:\n",
        "            mapping[col] = col_lower\n",
        "    \n",
        "    return mapping\n",
        "\n",
        "# Create mappings\n",
        "holdings_mapping = create_column_mapping(holdings_df.columns)\n",
        "trades_mapping = create_column_mapping(trades_df.columns)\n",
        "\n",
        "# Create column_mappings.json (database column names)\n",
        "column_mappings = {\n",
        "    \"holdings\": {\n",
        "        \"columns\": [holdings_mapping[col] for col in holdings_df.columns],\n",
        "        \"fund_column\": holdings_mapping.get(holdings_fund_col, \"portfolioname\"),\n",
        "        \"date_column\": holdings_mapping.get(holdings_date_col, \"asofdate\")\n",
        "    },\n",
        "    \"trades\": {\n",
        "        \"columns\": [trades_mapping[col] for col in trades_df.columns],\n",
        "        \"fund_column\": trades_mapping.get(trades_fund_col, \"portfolioname\"),\n",
        "        \"date_column\": trades_mapping.get(trades_date_col, \"tradedate\")\n",
        "    }\n",
        "}\n",
        "\n",
        "# Save column_mappings.json\n",
        "column_mappings_path = project_root / \"notebook2\" / \"column_mappings.json\"\n",
        "with open(column_mappings_path, \"w\") as f:\n",
        "    json.dump(column_mappings, f, indent=2)\n",
        "\n",
        "print(f\"✅ column_mappings.json saved to {column_mappings_path}\")\n",
        "print(f\"   Holdings: {len(column_mappings['holdings']['columns'])} columns\")\n",
        "print(f\"   Trades: {len(column_mappings['trades']['columns'])} columns\")\n",
        "print(f\"\\n   Key mappings:\")\n",
        "if 'plytd' in column_mappings['holdings']['columns']:\n",
        "    print(f\"     PL_YTD → plytd\")\n",
        "if 'mvbase' in column_mappings['holdings']['columns']:\n",
        "    print(f\"     MV_Base → mvbase\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python (fund-chatbot)",
      "language": "python",
      "name": "fund-chatbot"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
