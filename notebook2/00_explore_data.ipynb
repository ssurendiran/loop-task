{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 00: Data Exploration & Schema Discovery\n",
        "\n",
        "## Purpose\n",
        "This notebook explores the raw CSV files (`holdings.csv` and `trades.csv`) to understand their structure, identify key columns, detect data quality issues, and generate schema documentation.\n",
        "\n",
        "## Key Features\n",
        "- Loads and examines CSV files\n",
        "- Identifies fund identifiers, date columns, and P&L columns\n",
        "- Performs data quality checks (missing values, duplicates, anomalies)\n",
        "- Generates `schema_info.json` and `column_mappings.json` for downstream use\n",
        "\n",
        "## Column Mapping Strategy\n",
        "**IMPORTANT**: CSV files use different column names than the database:\n",
        "- CSV: `PL_YTD`, `PL_MTD`, `PL_QTD`, `PL_DTD` (uppercase with underscores)\n",
        "- Database: `plytd`, `plmtd`, `plqtd`, `pldtd` (lowercase, no underscores)\n",
        "- CSV: `MV_Base`, `MV_Local`, `PortfolioName` (PascalCase)\n",
        "- Database: `mvbase`, `mvlocal`, `portfolioname` (lowercase)\n",
        "\n",
        "This notebook documents the CSV structure. The mapping to database column names happens in `01_data_ingestion.ipynb`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Imports loaded\n",
            "   Data directory: /Users/suren/Desktop/untitled folder/loop-task/data\n"
          ]
        }
      ],
      "source": [
        "# Cell 1: Imports and Setup\n",
        "import pandas as pd\n",
        "import json\n",
        "from pathlib import Path\n",
        "from datetime import datetime, timezone\n",
        "\n",
        "# Project root\n",
        "project_root = Path.cwd().parent\n",
        "data_dir = project_root / \"data\"\n",
        "\n",
        "print(\"✅ Imports loaded\")\n",
        "print(f\"   Data directory: {data_dir}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Holdings loaded: 1022 rows, 25 columns\n",
            "✅ Trades loaded: 649 rows, 31 columns\n",
            "\n",
            "Holdings columns: ['AsOfDate', 'OpenDate', 'CloseDate', 'ShortName', 'PortfolioName', 'StrategyRefShortName', 'Strategy1RefShortName', 'Strategy2RefShortName', 'CustodianName', 'DirectionName', 'SecurityId', 'SecurityTypeName', 'SecName', 'StartQty', 'Qty', 'StartPrice', 'Price', 'StartFXRate', 'FXRate', 'MV_Local', 'MV_Base', 'PL_DTD', 'PL_QTD', 'PL_MTD', 'PL_YTD']\n",
            "\n",
            "Trades columns: ['id', 'RevisionId', 'AllocationId', 'TradeTypeName', 'SecurityId', 'SecurityType', 'Name', 'Ticker', 'CUSIP', 'ISIN', 'TradeDate', 'SettleDate', 'Quantity', 'Price', 'TradeFXRate', 'Principal', 'Interest', 'TotalCash', 'AllocationQTY', 'AllocationPrincipal', 'AllocationInterest', 'AllocationFees', 'AllocationCash', 'PortfolioName', 'CustodianName', 'StrategyName', 'Strategy1Name', 'Strategy2Name', 'Counterparty', 'AllocationRule', 'IsCustomAllocation']\n"
          ]
        }
      ],
      "source": [
        "# Cell 2: Load CSV Files\n",
        "holdings_file = data_dir / \"holdings.csv\"\n",
        "trades_file = data_dir / \"trades.csv\"\n",
        "\n",
        "# Load holdings\n",
        "holdings_df = pd.read_csv(holdings_file)\n",
        "print(f\"✅ Holdings loaded: {len(holdings_df)} rows, {len(holdings_df.columns)} columns\")\n",
        "\n",
        "# Load trades\n",
        "trades_df = pd.read_csv(trades_file)\n",
        "print(f\"✅ Trades loaded: {len(trades_df)} rows, {len(trades_df.columns)} columns\")\n",
        "\n",
        "# Display column names\n",
        "print(f\"\\nHoldings columns: {list(holdings_df.columns)}\")\n",
        "print(f\"\\nTrades columns: {list(trades_df.columns)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Holdings:\n",
            "  Fund column: PortfolioName\n",
            "  Date column: AsOfDate\n",
            "  P&L columns: ['PL_DTD', 'PL_QTD', 'PL_MTD', 'PL_YTD']\n",
            "\n",
            "Trades:\n",
            "  Fund column: PortfolioName\n",
            "  Date column: TradeDate\n",
            "  P&L columns: []\n"
          ]
        }
      ],
      "source": [
        "# Cell 3: Identify Key Columns\n",
        "\n",
        "def identify_fund_column(df: pd.DataFrame) -> str:\n",
        "    \"\"\"Identify fund identifier column.\"\"\"\n",
        "    candidates = [\"PortfolioName\", \"portfolioname\", \"Fund\", \"fund\"]\n",
        "    for col in candidates:\n",
        "        if col in df.columns:\n",
        "            return col\n",
        "    return None\n",
        "\n",
        "def identify_date_column(df: pd.DataFrame) -> str:\n",
        "    \"\"\"Identify date column.\"\"\"\n",
        "    candidates = [\"AsOfDate\", \"asofdate\", \"TradeDate\", \"tradedate\", \"Date\", \"date\"]\n",
        "    for col in candidates:\n",
        "        if col in df.columns:\n",
        "            return col\n",
        "    return None\n",
        "\n",
        "def identify_pnl_columns(df: pd.DataFrame) -> list:\n",
        "    \"\"\"Identify P&L columns (from CSV - may have underscores).\"\"\"\n",
        "    pnl_cols = []\n",
        "    for col in df.columns:\n",
        "        col_lower = col.lower()\n",
        "        if \"pl_ytd\" in col_lower or \"plytd\" in col_lower:\n",
        "            pnl_cols.append(col)\n",
        "        elif \"pl_mtd\" in col_lower or \"plmtd\" in col_lower:\n",
        "            pnl_cols.append(col)\n",
        "        elif \"pl_qtd\" in col_lower or \"plqtd\" in col_lower:\n",
        "            pnl_cols.append(col)\n",
        "        elif \"pl_dtd\" in col_lower or \"pldtd\" in col_lower:\n",
        "            pnl_cols.append(col)\n",
        "    return pnl_cols\n",
        "\n",
        "# Identify columns\n",
        "holdings_fund_col = identify_fund_column(holdings_df)\n",
        "holdings_date_col = identify_date_column(holdings_df)\n",
        "holdings_pnl_cols = identify_pnl_columns(holdings_df)\n",
        "\n",
        "trades_fund_col = identify_fund_column(trades_df)\n",
        "trades_date_col = identify_date_column(trades_df)\n",
        "trades_pnl_cols = identify_pnl_columns(trades_df)\n",
        "\n",
        "print(\"Holdings:\")\n",
        "print(f\"  Fund column: {holdings_fund_col}\")\n",
        "print(f\"  Date column: {holdings_date_col}\")\n",
        "print(f\"  P&L columns: {holdings_pnl_cols}\")\n",
        "\n",
        "print(\"\\nTrades:\")\n",
        "print(f\"  Fund column: {trades_fund_col}\")\n",
        "print(f\"  Date column: {trades_date_col}\")\n",
        "print(f\"  P&L columns: {trades_pnl_cols}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Holdings - Missing Data:\n",
            "  CloseDate: 1006 (98.4%)\n",
            "  MV_Local: 16 (1.6%)\n",
            "  MV_Base: 16 (1.6%)\n",
            "\n",
            "Holdings - Duplicates: 2 rows\n",
            "\n",
            "Holdings - Unique Funds: 19\n",
            "  Sample: ['Garfield', 'Heather', 'MNC Investment Fund', 'Northpoint 401K', 'CoYold 1', 'Opium Holdings Partners', 'Ytum', 'Platpot', 'Hi Yield', 'Warren Lee IG']\n",
            "\n",
            "Trades - Missing Data:\n",
            "  Ticker: 448 (69.0%)\n",
            "  CUSIP: 151 (23.3%)\n",
            "  ISIN: 125 (19.3%)\n",
            "  TradeFXRate: 649 (100.0%)\n",
            "  AllocationRule: 2 (0.3%)\n",
            "\n",
            "Trades - Duplicates: 0 rows\n",
            "\n",
            "Trades - Unique Funds: 16\n",
            "  Sample: ['HoldCo 1', 'HoldCo 3', 'HoldCo 11', 'HoldCo 7', 'Redfield Accu-Fund', 'UNC Investment Fund', 'ClientA', 'Leatherwood Trust MA', 'Platpot Fund', 'Optimum Holdings Partners']\n"
          ]
        }
      ],
      "source": [
        "# Cell 4: Data Quality Checks\n",
        "\n",
        "def check_missing_data(df: pd.DataFrame, name: str):\n",
        "    \"\"\"Check for missing values.\"\"\"\n",
        "    print(f\"\\n{name} - Missing Data:\")\n",
        "    for col in df.columns:\n",
        "        missing = df[col].isna().sum()\n",
        "        pct = (missing / len(df)) * 100\n",
        "        if missing > 0:\n",
        "            print(f\"  {col}: {missing} ({pct:.1f}%)\")\n",
        "\n",
        "def check_duplicates(df: pd.DataFrame, name: str):\n",
        "    \"\"\"Check for duplicate rows.\"\"\"\n",
        "    duplicates = df.duplicated().sum()\n",
        "    print(f\"\\n{name} - Duplicates: {duplicates} rows\")\n",
        "\n",
        "def check_unique_funds(df: pd.DataFrame, fund_col: str, name: str):\n",
        "    \"\"\"List unique funds.\"\"\"\n",
        "    if fund_col and fund_col in df.columns:\n",
        "        unique_funds = df[fund_col].unique()\n",
        "        print(f\"\\n{name} - Unique Funds: {len(unique_funds)}\")\n",
        "        print(f\"  Sample: {list(unique_funds[:10])}\")\n",
        "\n",
        "# Run checks\n",
        "check_missing_data(holdings_df, \"Holdings\")\n",
        "check_duplicates(holdings_df, \"Holdings\")\n",
        "check_unique_funds(holdings_df, holdings_fund_col, \"Holdings\")\n",
        "\n",
        "check_missing_data(trades_df, \"Trades\")\n",
        "check_duplicates(trades_df, \"Trades\")\n",
        "check_unique_funds(trades_df, trades_fund_col, \"Trades\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ schema_info.json saved to /Users/suren/Desktop/untitled folder/loop-task/notebook2/schema_info.json\n",
            "   Holdings: 25 columns\n",
            "   Trades: 31 columns\n"
          ]
        }
      ],
      "source": [
        "# Cell 5: Generate Schema Info\n",
        "\n",
        "# Create schema_info.json (CSV column names - for reference)\n",
        "schema_info = {\n",
        "    \"holdings\": {\n",
        "        \"columns\": list(holdings_df.columns),\n",
        "        \"fund_column\": holdings_fund_col,\n",
        "        \"date_column\": holdings_date_col,\n",
        "        \"pnl_columns\": holdings_pnl_cols,\n",
        "        \"shape\": list(holdings_df.shape),\n",
        "        \"dtypes\": {col: str(dtype) for col, dtype in holdings_df.dtypes.items()},\n",
        "        \"unique_funds\": int(holdings_df[holdings_fund_col].nunique()) if holdings_fund_col else 0,\n",
        "        \"sample_funds\": list(holdings_df[holdings_fund_col].unique()[:10]) if holdings_fund_col else []\n",
        "    },\n",
        "    \"trades\": {\n",
        "        \"columns\": list(trades_df.columns),\n",
        "        \"fund_column\": trades_fund_col,\n",
        "        \"date_column\": trades_date_col,\n",
        "        \"pnl_columns\": trades_pnl_cols,\n",
        "        \"shape\": list(trades_df.shape),\n",
        "        \"dtypes\": {col: str(dtype) for col, dtype in trades_df.dtypes.items()},\n",
        "        \"unique_funds\": int(trades_df[trades_fund_col].nunique()) if trades_fund_col else 0,\n",
        "        \"sample_funds\": list(trades_df[trades_fund_col].unique()[:10]) if trades_fund_col else []\n",
        "    }\n",
        "}\n",
        "\n",
        "# Save schema_info.json\n",
        "schema_info_path = project_root / \"notebook2\" / \"schema_info.json\"\n",
        "with open(schema_info_path, \"w\") as f:\n",
        "    json.dump(schema_info, f, indent=2)\n",
        "\n",
        "print(f\"✅ schema_info.json saved to {schema_info_path}\")\n",
        "print(f\"   Holdings: {len(schema_info['holdings']['columns'])} columns\")\n",
        "print(f\"   Trades: {len(schema_info['trades']['columns'])} columns\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ column_mappings.json saved to /Users/suren/Desktop/untitled folder/loop-task/notebook2/column_mappings.json\n",
            "   Holdings: 25 columns\n",
            "   Trades: 31 columns\n",
            "\n",
            "   Key mappings:\n",
            "     PL_YTD → plytd\n",
            "     MV_Base → mvbase\n"
          ]
        }
      ],
      "source": [
        "# Cell 6: Generate Column Mappings (CSV → Database)\n",
        "\n",
        "# CRITICAL: This mapping converts CSV column names to database column names\n",
        "# Database uses lowercase, no underscores for P&L columns\n",
        "\n",
        "def create_column_mapping(csv_columns: list) -> dict:\n",
        "    \"\"\"Create mapping from CSV columns to database columns.\"\"\"\n",
        "    mapping = {}\n",
        "    \n",
        "    for col in csv_columns:\n",
        "        col_lower = col.lower()\n",
        "        \n",
        "        # P&L columns: PL_YTD → plytd, PL_MTD → plmtd, etc.\n",
        "        if \"pl_ytd\" in col_lower or col_lower == \"plytd\":\n",
        "            mapping[col] = \"plytd\"\n",
        "        elif \"pl_mtd\" in col_lower or col_lower == \"plmtd\":\n",
        "            mapping[col] = \"plmtd\"\n",
        "        elif \"pl_qtd\" in col_lower or col_lower == \"plqtd\":\n",
        "            mapping[col] = \"plqtd\"\n",
        "        elif \"pl_dtd\" in col_lower or col_lower == \"pldtd\":\n",
        "            mapping[col] = \"pldtd\"\n",
        "        # Market value columns\n",
        "        elif \"mv_base\" in col_lower or col_lower == \"mvbase\":\n",
        "            mapping[col] = \"mvbase\"\n",
        "        elif \"mv_local\" in col_lower or col_lower == \"mvlocal\":\n",
        "            mapping[col] = \"mvlocal\"\n",
        "        # Other columns: convert to lowercase\n",
        "        else:\n",
        "            mapping[col] = col_lower\n",
        "    \n",
        "    return mapping\n",
        "\n",
        "# Create mappings\n",
        "holdings_mapping = create_column_mapping(holdings_df.columns)\n",
        "trades_mapping = create_column_mapping(trades_df.columns)\n",
        "\n",
        "# Create column_mappings.json (database column names)\n",
        "column_mappings = {\n",
        "    \"holdings\": {\n",
        "        \"columns\": [holdings_mapping[col] for col in holdings_df.columns],\n",
        "        \"fund_column\": holdings_mapping.get(holdings_fund_col, \"portfolioname\"),\n",
        "        \"date_column\": holdings_mapping.get(holdings_date_col, \"asofdate\")\n",
        "    },\n",
        "    \"trades\": {\n",
        "        \"columns\": [trades_mapping[col] for col in trades_df.columns],\n",
        "        \"fund_column\": trades_mapping.get(trades_fund_col, \"portfolioname\"),\n",
        "        \"date_column\": trades_mapping.get(trades_date_col, \"tradedate\")\n",
        "    }\n",
        "}\n",
        "\n",
        "# Save column_mappings.json\n",
        "column_mappings_path = project_root / \"notebook2\" / \"column_mappings.json\"\n",
        "with open(column_mappings_path, \"w\") as f:\n",
        "    json.dump(column_mappings, f, indent=2)\n",
        "\n",
        "print(f\"✅ column_mappings.json saved to {column_mappings_path}\")\n",
        "print(f\"   Holdings: {len(column_mappings['holdings']['columns'])} columns\")\n",
        "print(f\"   Trades: {len(column_mappings['trades']['columns'])} columns\")\n",
        "print(f\"\\n   Key mappings:\")\n",
        "if 'plytd' in column_mappings['holdings']['columns']:\n",
        "    print(f\"     PL_YTD → plytd\")\n",
        "if 'mvbase' in column_mappings['holdings']['columns']:\n",
        "    print(f\"     MV_Base → mvbase\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
